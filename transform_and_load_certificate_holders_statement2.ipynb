{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d0cff7a-35ce-4cb7-b7f2-cef1440b00c6",
   "metadata": {},
   "source": [
    "### Transform key values from the extracted Certificate Holders Statement pdf files into csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ac6d869-61d2-47e5-8e1a-8e2317d3fb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction complete. Data saved to C:\\Users\\Rex Fuentes\\Documents\\breakdown_of_principal.csv\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Directory where PDF files are stored\n",
    "pdf_directory = r\"C:\\Users\\Rex Fuentes\\Documents\\Data Engineering Case Study\\citigroup_case_study\\certfc8_holdrs_st8mnt\"\n",
    "csv_filename = r\"C:\\Users\\Rex Fuentes\\Documents\\Data Engineering Case Study\\citigroup_case_study\\breakdown_of_principal.csv\"\n",
    "\n",
    "# Check if the directory exists, and if not, create it\n",
    "csv_directory = os.path.dirname(csv_filename)\n",
    "if not os.path.exists(csv_directory):\n",
    "    os.makedirs(csv_directory)\n",
    "\n",
    "# Regular expression patterns for extracting data\n",
    "distribution_date_pattern = r\"Distribution Date:\\s*(\\d{1,2}/\\d{1,2}/\\d{4})\"\n",
    "determination_date_pattern = r\"(\\d{1,2}/\\d{1,2}/\\d{4})\\s*Determination Date:\"\n",
    "total_principal_pattern = r\"Total Principal Funds Available:\\s*\\$?([\\d,]+\\.\\d{2})\"\n",
    "scheduled_principal_pattern = r\"Scheduled Principal\\s*\\$?([\\d,]+\\.\\d{2})\"\n",
    "curtailments_pattern = r\"Curtailments\\s*\\$?\\(?([\\d,]+\\.\\d{2})\\)?\"\n",
    "prepayments_pattern = r\"Prepayments in Full\\s*\\$?([\\d,]+\\.\\d{2})\"\n",
    "net_liquidation_proceeds_pattern = r\"Net Liquidation Proceeds\\s*\\$?\\(?([\\d,]+\\.\\d{2})\\)?\"\n",
    "\n",
    "def extract_value_from_text(pattern, text):\n",
    "    match = re.search(pattern, text)\n",
    "    if match:\n",
    "        value = match.group(1).replace(',', '')\n",
    "        if '(' in match.group(0) and ')' in match.group(0):\n",
    "            value = '-' + value\n",
    "        return value\n",
    "    elif 'Net Liquidation Proceeds' in text or 'Curtailments' in text or 'Prepayments in Full' in text:\n",
    "        return '0.00'\n",
    "    else:\n",
    "        return \"Not found\"\n",
    "\n",
    "def extract_data_from_pdf(pdf_path):\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "\n",
    "    # Check for the unique marker \"Page 1\" on the first page\n",
    "    page_one_text = pdf_document[0].get_text() if len(pdf_document) > 0 else \"\"\n",
    "    page_one_present = re.search(r\"Page 1\\b\", page_one_text) is not None\n",
    "\n",
    "    # Use page 6 if page 1 is present, else use page 5\n",
    "    target_page_index = 5 if page_one_present else 4\n",
    "\n",
    "    # Extract text from the target page\n",
    "    if len(pdf_document) > target_page_index:\n",
    "        page_text = pdf_document[target_page_index].get_text()\n",
    "        distribution_date = extract_value_from_text(distribution_date_pattern, page_text)\n",
    "        determination_date = extract_value_from_text(determination_date_pattern, page_text)\n",
    "        total_principal = extract_value_from_text(total_principal_pattern, page_text)\n",
    "        scheduled_principal = extract_value_from_text(scheduled_principal_pattern, page_text)\n",
    "        curtailments = extract_value_from_text(curtailments_pattern, page_text)\n",
    "        prepayments = extract_value_from_text(prepayments_pattern, page_text)\n",
    "        net_liquidation_proceeds = extract_value_from_text(net_liquidation_proceeds_pattern, page_text)\n",
    "    else:\n",
    "        # Set all values to \"Not found\" if the target page does not exist\n",
    "        distribution_date = determination_date = total_principal = scheduled_principal = curtailments = prepayments = net_liquidation_proceeds = \"Not found\"\n",
    "\n",
    "    pdf_document.close()\n",
    "    return (\n",
    "        distribution_date, determination_date, total_principal, scheduled_principal, curtailments, prepayments, net_liquidation_proceeds\n",
    "    )\n",
    "\n",
    "# Write the headers to the CSV file\n",
    "with open(csv_filename, 'w', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    headers = [\n",
    "        'Filename', 'Distribution Date', 'Determination Date', 'Total Principal Funds Available',\n",
    "        'Scheduled Principal', 'Curtailments', 'Prepayments in Full', 'Net Liquidation Proceeds'\n",
    "    ]\n",
    "    csv_writer.writerow(headers)\n",
    "\n",
    "    # Iterate over each PDF file in the directory\n",
    "    for filename in os.listdir(pdf_directory):\n",
    "        if filename.lower().endswith('.pdf'):\n",
    "            pdf_path = os.path.join(pdf_directory, filename)\n",
    "            data = extract_data_from_pdf(pdf_path)\n",
    "            csv_writer.writerow([filename] + list(data))\n",
    "\n",
    "print(\"Transformation complete. Data saved to\", csv_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94f860a-b2cf-44da-9c9c-6fc0273f5275",
   "metadata": {},
   "source": [
    "### Loads the csv file to the citigroup database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "359119e5-5954-48bc-ad4c-13150b678994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data completed. All empty columns were dropped.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "import configparser\n",
    "\n",
    "# Function to drop entirely empty columns\n",
    "def drop_empty_columns(df):\n",
    "    return df.dropna(axis=1, how='all')\n",
    "\n",
    "# Read database credentials and file directory from a config file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "# Database connection URL\n",
    "db_connection_url = f\"postgresql+psycopg2://{config['database']['user']}:{config['database']['password']}@{config['database']['host']}:{config['database']['port']}/{config['database']['database']}\"\n",
    "\n",
    "# Create a SQLAlchemy engine\n",
    "engine = create_engine(db_connection_url)\n",
    "\n",
    "# Directory where your CSV files are stored\n",
    "csv_folder_path = config['files']['csv_file_path_of_transformed_pdf']\n",
    "\n",
    "# Check if the path is a directory\n",
    "if os.path.isdir(csv_folder_path):\n",
    "    # Iterate over each file in the folder and insert data into the database\n",
    "    for csv_file in os.listdir(csv_folder_path):\n",
    "        if csv_file.endswith('.csv'):\n",
    "            file_path = os.path.join(csv_folder_path, csv_file)\n",
    "\n",
    "            # Use Pandas to load the CSV file\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            # Drop columns that are entirely empty\n",
    "            df = drop_empty_columns(df)\n",
    "\n",
    "            # Use 'to_sql' to insert the data into the database, it creates a table if it does not exist\n",
    "            df.to_sql('transformed_pdf', engine, if_exists='append', index=False)\n",
    "\n",
    "    print(\"Loading data completed. All empty columns were dropped.\")\n",
    "else:\n",
    "    print(f\"The provided path is not a directory: {csv_folder_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ab21fb-7f60-4061-a5ea-53eeda77c140",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
