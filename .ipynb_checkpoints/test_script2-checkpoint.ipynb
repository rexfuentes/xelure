{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9430a7e7-2cf4-4689-bc77-9c9b01406232",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import os\n",
    "import pandas as pd\n",
    "import configparser\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Read database credentials and file directory from a config file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "# Set the new download directory path using raw string\n",
    "download_dir = r\"C:\\Users\\Rex Fuentes\\Documents\\citigroup_case_study\\enhanced_lld2\"\n",
    "\n",
    "# Set preferences for Chrome Options\n",
    "prefs = {\"download.default_directory\": download_dir}\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_experimental_option(\"prefs\", prefs)\n",
    "\n",
    "# Initialize WebDriver\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# Define the URL of the website and navigate to it\n",
    "url = 'https://sf.citidirect.com/stfin/index.html'\n",
    "driver.get(url)\n",
    "\n",
    "# Wait until the ready state is complete\n",
    "WebDriverWait(driver, 60).until(lambda d: d.execute_script('return document.readyState') == 'complete')\n",
    "\n",
    "# Switch to the frame that contains the 'MBS' link\n",
    "driver.switch_to.frame(\"left\")\n",
    "\n",
    "# Wait for the 'MBS' link to be clickable and click it\n",
    "try:\n",
    "    mbs_link = WebDriverWait(driver, 60).until(EC.element_to_be_clickable((By.ID, 'MBS')))\n",
    "    mbs_link.click()\n",
    "except TimeoutException:\n",
    "    print(\"Timed out waiting for the 'MBS' link to be clickable.\")\n",
    "    driver.quit()\n",
    "    exit()\n",
    "\n",
    "# Switch back to the main content and then to the frame that contains the '2006-AMC1' link\n",
    "driver.switch_to.default_content()\n",
    "try:\n",
    "    WebDriverWait(driver, 60).until(EC.frame_to_be_available_and_switch_to_it((By.NAME, \"main\")))\n",
    "    print(\"Switched to main frame.\")\n",
    "except TimeoutException:\n",
    "    print(\"Timed out waiting for the main frame to be available.\")\n",
    "    driver.quit()\n",
    "    exit()\n",
    "\n",
    "# Click the '2006-AMC1' link\n",
    "try:\n",
    "    link_2006_AMC1 = WebDriverWait(driver, 60).until(EC.element_to_be_clickable((By.XPATH, \"//a[normalize-space(.)='2006-AMC1']\")))\n",
    "    link_2006_AMC1.click()\n",
    "except TimeoutException:\n",
    "    print(\"Timed out waiting for the '2006-AMC1' link to be clickable.\")\n",
    "    driver.quit()\n",
    "    exit()\n",
    "\n",
    "# Set up the XPath pattern to match the PDF link for each month of a specific year\n",
    "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "# XPath pattern to match the PDF link for each month taking into account the preceding sibling with year\n",
    "years = [str(year) for year in range(2006, 2024)]\n",
    "\n",
    "for year in years:\n",
    "    for month in months:\n",
    "        xpath = f\"//td[preceding-sibling::td[contains(., '{year}')]]\" \\\n",
    "        f\"/a[translate(@class, 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz')='nodec1bold' \" \\\n",
    "        f\"and contains(translate(@href, 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz'), 'loandetailcml') \" \\\n",
    "        f\"and contains(., '{month}')]\"\n",
    "        try:\n",
    "            # Wait for the link to be clickable and click it\n",
    "            month_link = WebDriverWait(driver, 60).until(EC.element_to_be_clickable((By.XPATH, xpath)))\n",
    "            month_link.click()\n",
    "            print(f\"Clicked on the PDF link for {month} {year}\")\n",
    "           \n",
    "        except TimeoutException:\n",
    "            print(f\"Could not find the clickable PDF link for {month} {year}\")\n",
    "        except NoSuchElementException:\n",
    "            print(f\"Could not find the link for {month} {year}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred: {e}\")\n",
    "            driver.quit()\n",
    "            exit()\n",
    "\n",
    "# Close the browser after the operations are complete\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23aeae94-b30f-40a9-88a7-1ac9b9e68832",
   "metadata": {},
   "source": [
    "# ELLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0b397df-c0b1-4af7-87b2-0daa0826b130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched to main frame.\n",
      "Could not find the clickable link for Jan 2007\n",
      "Could not find the clickable link for Feb 2007\n",
      "Could not find the clickable link for Mar 2007\n",
      "Could not find the clickable link for Apr 2007\n",
      "Could not find the clickable link for May 2007\n",
      "Could not find the clickable link for Jun 2007\n",
      "Clicked on the link for Jul 2007\n",
      "Clicked on the link for Aug 2007\n",
      "Clicked on the link for Sep 2007\n",
      "Clicked on the link for Oct 2007\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 99\u001b[0m\n\u001b[0;32m     97\u001b[0m             driver\u001b[38;5;241m.\u001b[39mquit()\n\u001b[0;32m     98\u001b[0m             exit()\n\u001b[1;32m---> 99\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Wait for download to complete\u001b[39;00m\n\u001b[0;32m    101\u001b[0m driver\u001b[38;5;241m.\u001b[39mquit()\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtraction complete.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "\n",
    "# Read database credentials and file directory from a config file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "# Directory where CSV files will be downloaded\n",
    "csv_directory = config['files']['enhanced_loan_level_dir2']\n",
    "\n",
    "# Selenium setup for web scraping and file download\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "prefs = {\"download.default_directory\": csv_directory}\n",
    "chrome_options.add_experimental_option(\"prefs\", prefs)\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# Define the URL of the website and navigate to it\n",
    "url = 'https://sf.citidirect.com/stfin/index.html'\n",
    "driver.get(url)\n",
    "\n",
    "# Web scraping code to download CSV files...\n",
    "# Wait until the ready state is complete\n",
    "WebDriverWait(driver, 60).until(lambda d: d.execute_script('return document.readyState') == 'complete')\n",
    "\n",
    "# Switch to the frame that contains the 'MBS' link\n",
    "driver.switch_to.frame(\"left\")\n",
    "\n",
    "# Wait for the 'MBS' link to be clickable and click it\n",
    "try:\n",
    "    mbs_link = WebDriverWait(driver, 60).until(EC.element_to_be_clickable((By.ID, 'MBS')))\n",
    "    mbs_link.click()\n",
    "except TimeoutException:\n",
    "    print(\"Timed out waiting for the 'MBS' link to be clickable.\")\n",
    "    driver.quit()\n",
    "    exit()\n",
    "\n",
    "# Switch back to the main content and then to the frame that contains the '2006-AMC1' link\n",
    "driver.switch_to.default_content()\n",
    "try:\n",
    "    WebDriverWait(driver, 60).until(EC.frame_to_be_available_and_switch_to_it((By.NAME, \"main\")))\n",
    "    print(\"Switched to main frame.\")\n",
    "except TimeoutException:\n",
    "    print(\"Timed out waiting for the main frame to be available.\")\n",
    "    driver.quit()\n",
    "    exit()\n",
    "\n",
    "# Click the '2006-AMC1' link\n",
    "try:\n",
    "    link_2006_AMC1 = WebDriverWait(driver, 60).until(EC.element_to_be_clickable((By.XPATH, \"//a[normalize-space(.)='2006-AMC1']\")))\n",
    "    link_2006_AMC1.click()\n",
    "except TimeoutException:\n",
    "    print(\"Timed out waiting for the '2006-AMC1' link to be clickable.\")\n",
    "    driver.quit()\n",
    "    exit()\n",
    "\n",
    "# Function to get the most recently downloaded file\n",
    "def get_latest_downloaded_file(download_dir):\n",
    "    # Get list of files in the directory sorted by modified time\n",
    "    files = [os.path.join(download_dir, f) for f in os.listdir(download_dir)]\n",
    "    files.sort(key=lambda x: os.path.getmtime(x), reverse=True)\n",
    "    if files:\n",
    "        return files[0]\n",
    "    return None\n",
    "\n",
    "# Set up the XPath pattern to match the PDF link for each month of a specific year\n",
    "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "# XPath pattern to match the PDF link for each month taking into account the preceding sibling with year\n",
    "years = [str(year) for year in range(2007, 2023)]\n",
    "\n",
    "for year in years:\n",
    "    for month in months:\n",
    "        xpath = f\"//td[preceding-sibling::td[contains(., '{year}')]]\" \\\n",
    "        f\"/a[translate(@class, 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz')='nodec1bold' \" \\\n",
    "        f\"and contains(translate(@href, 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz'), 'loandetailcml') \" \\\n",
    "        f\"and contains(., '{month}')]\"\n",
    "        try:\n",
    "            # Wait for the link to be clickable and click it\n",
    "            month_link = WebDriverWait(driver, 60).until(EC.element_to_be_clickable((By.XPATH, xpath)))\n",
    "            month_link.click()\n",
    "            print(f\"Clicked on the link for {month} {year}\")\n",
    "           \n",
    "        except TimeoutException:\n",
    "            print(f\"Could not find the clickable link for {month} {year}\")\n",
    "        except NoSuchElementException:\n",
    "            print(f\"Could not find the link for {month} {year}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred: {e}\")\n",
    "            driver.quit()\n",
    "            exit()\n",
    "        time.sleep(10)  # Wait for download to complete\n",
    "       \n",
    "driver.quit()\n",
    "\n",
    "print(\"Extraction complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a463dcc2-286d-4f96-b481-3ced971b4335",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0414dadb-b97a-4f06-ae66-8fbdc250b5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    " time.sleep(20)  # Wait for download to complete\n",
    "\n",
    "        # Identify the most recently downloaded file\n",
    "        downloaded_file = get_latest_downloaded_file(csv_directory)\n",
    "        if downloaded_file:\n",
    "            # Construct new filename with original name, month, and year\n",
    "            file_base_name = os.path.basename(downloaded_file)\n",
    "            new_filename = f\"{os.path.splitext(file_base_name)[0]}_{month}_{year}{os.path.splitext(file_base_name)[1]}\"\n",
    "            new_file_path = os.path.join(csv_directory, new_filename)\n",
    "\n",
    "            # Rename the file\n",
    "            os.rename(downloaded_file, new_file_path)\n",
    "        else:\n",
    "            print(f\"No file was downloaded for {month} {year}\")\n",
    "        \n",
    "\n",
    "\n",
    "# SQLAlchemy connection URL\n",
    "connection_url = f\"postgresql://{config['database']['user']}:{config['database']['password']}@{config['database']['host']}:{config['database']['port']}/{config['database']['database']}\"\n",
    "\n",
    "# Create SQLAlchemy engine\n",
    "engine = create_engine(connection_url)\n",
    "\n",
    "# Function to extract month and year from filename\n",
    "def extract_month_year(filename):\n",
    "    # Assuming filename format is like 'data_January_2022.csv'\n",
    "    parts = filename.split('_')\n",
    "    if len(parts) >= 3:\n",
    "        month = parts[1]\n",
    "        year = parts[2].split('.')[0]  # Splitting to remove '.csv'\n",
    "        return month, year\n",
    "    return None, None\n",
    "\n",
    "# Iterate over each CSV file in the csv_directory\n",
    "for filename in os.listdir(csv_directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(csv_directory, filename)\n",
    "\n",
    "        # Read CSV into DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Extract month and year from filename and add as columns\n",
    "        month, year = extract_month_year(filename)\n",
    "        if month and year:\n",
    "            df['month_listed'] = month\n",
    "            df['year_listed'] = year\n",
    "\n",
    "        # Load the DataFrame into PostgreSQL\n",
    "        try:\n",
    "            df.to_sql('loan_level_data', engine, if_exists='append', index=False)\n",
    "            print(f\"Loaded {filename} into the database.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {filename}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d563de84-f8cf-4dab-8b1c-55e691712a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "import configparser\n",
    "\n",
    "# Read database credentials and file directory from a config file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "# Database connection URL\n",
    "db_connection_url = f\"postgresql+psycopg2://{config['database']['user']}:{config['database']['password']}@{config['database']['host']}:{config['database']['port']}/{config['database']['database']}\"\n",
    "\n",
    "# Create a SQLAlchemy engine\n",
    "engine = create_engine(db_connection_url)\n",
    "\n",
    "# Directory where your CSV files are stored\n",
    "csv_folder_path = config['files']['loan_level_data_download_dir']\n",
    "\n",
    "# Iterate over each file in the folder and insert data into the database\n",
    "for csv_file in os.listdir(csv_folder_path):\n",
    "    if csv_file.endswith('.csv'):\n",
    "        file_path = os.path.join(csv_folder_path, csv_file)\n",
    "\n",
    "        # Use Pandas to load the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Add a new column with the filename\n",
    "        df['filename'] = csv_file\n",
    "\n",
    "        # Use 'to_sql' to insert the data into the database, it creates a table if it does not exist\n",
    "        df.to_sql('loan_level_data', engine, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e26689-eb50-4c6e-ad1e-ab4ca3447f73",
   "metadata": {},
   "source": [
    "# Using the function convert_column_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126e46a2-5024-4bc7-91f7-d2d37f365b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "import configparser\n",
    "import numpy as np\n",
    "\n",
    "def convert_column_types(df):\n",
    "    for col in df.columns:\n",
    "        # Attempt to convert each column to numeric, and if not possible, leave as is\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(df[col])\n",
    "    return df\n",
    "\n",
    "# Read database credentials and file directory from a config file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "# Database connection URL\n",
    "db_connection_url = f\"postgresql+psycopg2://{config['database']['user']}:{config['database']['password']}@{config['database']['host']}:{config['database']['port']}/{config['database']['database']}\"\n",
    "\n",
    "# Create a SQLAlchemy engine\n",
    "engine = create_engine(db_connection_url)\n",
    "\n",
    "# Directory where your CSV files are stored\n",
    "csv_folder_path = config['files']['loan_level_data_download_dir']\n",
    "\n",
    "# Iterate over each file in the folder and insert data into the database\n",
    "for csv_file in os.listdir(csv_folder_path):\n",
    "    if csv_file.endswith('.csv'):\n",
    "        file_path = os.path.join(csv_folder_path, csv_file)\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Convert data types and handle NaN values\n",
    "        df = convert_column_types(df)\n",
    "        df = df.where(pd.notnull(df), None)\n",
    "\n",
    "        # Add a new column with the filename\n",
    "        df['source_filename'] = csv_file\n",
    "\n",
    "        # Insert data into the database\n",
    "        try:\n",
    "            df.to_sql('loan_level_data', engine, if_exists='append', index=False, method='multi')\n",
    "        except Exception as e:\n",
    "            print(f\"Error inserting file {csv_file}: {e}\")\n",
    "\n",
    "# Close the engine\n",
    "engine.dispose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de359302-5d63-4eb5-b04c-5f0bbf103933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "import configparser\n",
    "\n",
    "# Read database credentials and file directory from a config file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "# Database connection URL\n",
    "db_connection_url = f\"postgresql+psycopg2://{config['database']['user']}:{config['database']['password']}@{config['database']['host']}:{config['database']['port']}/{config['database']['database']}\"\n",
    "\n",
    "# Create a SQLAlchemy engine\n",
    "engine = create_engine(db_connection_url)\n",
    "\n",
    "# Directory where your CSV files are stored\n",
    "csv_folder_path = config['files']['enhanced_loan_level_dir']\n",
    "\n",
    "# Iterate over each file in the folder and insert data into the database\n",
    "for csv_file in os.listdir(csv_folder_path):\n",
    "    if csv_file.endswith('.csv'):\n",
    "        file_path = os.path.join(csv_folder_path, csv_file)\n",
    "\n",
    "        # Use Pandas to load the CSV file, treating all data as text\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Use 'to_sql' to insert the data into the database, it creates a table if it does not exist\n",
    "        df.to_sql('enhanced_loan_level_dir', engine, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f0f4b2-e093-4923-849c-0b0ce14ec989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Directory where your CSV files are stored\n",
    "csv_folder_path = r\"C:\\Users\\Rex Fuentes\\Documents\\citigroup_case_study\\enhanced_loan_level_data\"  \n",
    "\n",
    "# Column name to check\n",
    "column_name = \"Beginning Deferred Balance\"\n",
    "\n",
    "# List to store names of files containing the column\n",
    "files_with_column = []\n",
    "\n",
    "# Iterate over each file in the folder\n",
    "for csv_file in os.listdir(csv_folder_path):\n",
    "    if csv_file.endswith('.csv'):\n",
    "        file_path = os.path.join(csv_folder_path, csv_file)\n",
    "\n",
    "        # Use Pandas to read the first row of the CSV file\n",
    "        df = pd.read_csv(file_path, nrows=1)\n",
    "\n",
    "        # Check if the column exists\n",
    "        if column_name in df.columns:\n",
    "            files_with_column.append(csv_file)\n",
    "\n",
    "# Display the list of files that contain the column\n",
    "print(\"Files containing the column '{}':\".format(column_name))\n",
    "for file in files_with_column:\n",
    "    print(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ff0558-94f8-4026-af7b-35e6b04af6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Directory where your CSV files are stored\n",
    "csv_folder_path = r\"C:\\Users\\Rex Fuentes\\Documents\\citigroup_case_study\\enhanced_loan_level_data\"  \n",
    "\n",
    "# Column name to check\n",
    "column_name = \"Beginning Deferred Balance\"\n",
    "\n",
    "# Lists to store names of files containing the column\n",
    "files_with_column = []\n",
    "files_with_empty_column = []\n",
    "\n",
    "# Iterate over each file in the folder\n",
    "for csv_file in os.listdir(csv_folder_path):\n",
    "    if csv_file.endswith('.csv'):\n",
    "        file_path = os.path.join(csv_folder_path, csv_file)\n",
    "\n",
    "        # Use Pandas to read the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Check if the column exists\n",
    "        if column_name in df.columns:\n",
    "            files_with_column.append(csv_file)\n",
    "\n",
    "            # Check if the column is entirely empty\n",
    "            if df[column_name].isnull().all():\n",
    "                files_with_empty_column.append(csv_file)\n",
    "\n",
    "# Display the list of files that contain the column\n",
    "print(\"Files containing the column '{}':\".format(column_name))\n",
    "for file in files_with_column:\n",
    "    print(file)\n",
    "\n",
    "# Display the list of files where the column is entirely empty\n",
    "print(\"\\nFiles with an entirely empty column '{}':\".format(column_name))\n",
    "for file in files_with_empty_column:\n",
    "    print(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ed8185-6a5e-489f-bb2f-9eafad0885e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Directory where your CSV files are stored\n",
    "csv_folder_path = r\"C:\\Users\\Rex Fuentes\\Documents\\citigroup_case_study\\enhanced_loan_level_data\"\n",
    "\n",
    "# Column name to check\n",
    "column_name = \"Ending Deferred Balance\"\n",
    "\n",
    "# Variable to keep track of the column's emptiness across all files\n",
    "is_column_empty_in_all_files = True\n",
    "\n",
    "# Iterate over each file in the folder\n",
    "for csv_file in os.listdir(csv_folder_path):\n",
    "    if csv_file.endswith('.csv'):\n",
    "        file_path = os.path.join(csv_folder_path, csv_file)\n",
    "\n",
    "        # Use Pandas to read the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Check if the column exists\n",
    "        if column_name in df.columns:\n",
    "            # Check if the column is entirely empty\n",
    "            if not df[column_name].isnull().all():\n",
    "                is_column_empty_in_all_files = False\n",
    "                break  # No need to check further if one file has non-empty values\n",
    "\n",
    "# Display the result\n",
    "if is_column_empty_in_all_files:\n",
    "    print(f\"All files with the column '{column_name}' have it entirely empty.\")\n",
    "else:\n",
    "    print(f\"There are files with non-empty values in the '{column_name}' column.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16c0655-5164-49cd-9a49-38539110611d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "# Directory where your CSV files are stored\n",
    "csv_folder_path = r\"C:\\Users\\Rex Fuentes\\Documents\\citigroup_case_study\\enhanced_loan_level_data\"\n",
    "\n",
    "# Dictionary to keep track of empty columns across all files\n",
    "empty_columns = defaultdict(lambda: True)  # Assume all columns are empty initially\n",
    "\n",
    "# Iterate over each file in the folder\n",
    "for csv_file in os.listdir(csv_folder_path):\n",
    "    if csv_file.endswith('.csv'):\n",
    "        file_path = os.path.join(csv_folder_path, csv_file)\n",
    "\n",
    "        # Use Pandas to read the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Check each column in the DataFrame\n",
    "        for column in df.columns:\n",
    "            # If a column is found to be non-empty in any file, mark it as such\n",
    "            if empty_columns[column] and not df[column].isnull().all():\n",
    "                empty_columns[column] = False\n",
    "\n",
    "# Filter out the columns that are not empty in any file\n",
    "entirely_empty_columns = [col for col, is_empty in empty_columns.items() if is_empty]\n",
    "\n",
    "# Display the list of entirely empty columns across all files\n",
    "print(\"Entirely empty columns across all files:\")\n",
    "for col in entirely_empty_columns:\n",
    "    print(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ebebf1-c2c4-48df-96ac-a1f11d956565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "# Directory where your CSV files are stored\n",
    "csv_folder_path = r\"C:\\Users\\Rex Fuentes\\Documents\\citigroup_case_study\\loan_level_data\"\n",
    "\n",
    "# Dictionary to keep track of empty columns across all files\n",
    "empty_columns = defaultdict(lambda: True)  # Assume all columns are empty initially\n",
    "\n",
    "# Iterate over each file in the folder\n",
    "for csv_file in os.listdir(csv_folder_path):\n",
    "    if csv_file.endswith('.csv'):\n",
    "        file_path = os.path.join(csv_folder_path, csv_file)\n",
    "\n",
    "        # Use Pandas to read the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Check each column in the DataFrame\n",
    "        for column in df.columns:\n",
    "            # If a column is found to be non-empty in any file, mark it as such\n",
    "            if empty_columns[column] and not df[column].isnull().all():\n",
    "                empty_columns[column] = False\n",
    "\n",
    "# Filter out the columns that are not empty in any file\n",
    "entirely_empty_columns = [col for col, is_empty in empty_columns.items() if is_empty]\n",
    "\n",
    "# Display the list of entirely empty columns across all files\n",
    "print(\"Entirely empty columns across all files:\")\n",
    "for col in entirely_empty_columns:\n",
    "    print(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa234480-37db-4d6f-a2b3-9c87d3261f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "import configparser\n",
    "\n",
    "# Function to drop entirely empty columns\n",
    "def drop_empty_columns(df):\n",
    "    return df.dropna(axis=1, how='all')\n",
    "\n",
    "# Read database credentials and file directory from a config file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "# Database connection URL\n",
    "db_connection_url = f\"postgresql+psycopg2://{config['database']['user']}:{config['database']['password']}@{config['database']['host']}:{config['database']['port']}/{config['database']['database']}\"\n",
    "\n",
    "# Create a SQLAlchemy engine\n",
    "engine = create_engine(db_connection_url)\n",
    "\n",
    "# Directory where your CSV files are stored\n",
    "csv_folder_path = config['files']['enhanced_loan_level_dir']\n",
    "\n",
    "# Iterate over each file in the folder and insert data into the database\n",
    "for csv_file in os.listdir(csv_folder_path):\n",
    "    if csv_file.endswith('.csv'):\n",
    "        file_path = os.path.join(csv_folder_path, csv_file)\n",
    "\n",
    "        # Use Pandas to load the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Drop columns that are entirely empty\n",
    "        df = drop_empty_columns(df)\n",
    "\n",
    "        # Use 'to_sql' to insert the data into the database, it creates a table if it does not exist\n",
    "        df.to_sql('enhanced_loan_level_dir', engine, if_exists='append', index=False)\n",
    "\n",
    "print(\"Loading data completed. All empty columns were dropped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d786f13-e8ae-4183-a60d-47b7a6e8de1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "import configparser\n",
    "\n",
    "# Function to drop entirely empty columns\n",
    "def drop_empty_columns(df):\n",
    "    return df.dropna(axis=1, how='all')\n",
    "\n",
    "# Read database credentials and file directory from a config file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "# Database connection URL\n",
    "db_connection_url = f\"postgresql+psycopg2://{config['database']['user']}:{config['database']['password']}@{config['database']['host']}:{config['database']['port']}/{config['database']['database']}\"\n",
    "\n",
    "# Create a SQLAlchemy engine\n",
    "engine = create_engine(db_connection_url)\n",
    "\n",
    "# Directory where your CSV files are stored\n",
    "csv_folder_path = config['files']['loan_level_data_download_dir']\n",
    "\n",
    "# Iterate over each file in the folder and insert data into the database\n",
    "for csv_file in os.listdir(csv_folder_path):\n",
    "    if csv_file.endswith('.csv'):\n",
    "        file_path = os.path.join(csv_folder_path, csv_file)\n",
    "\n",
    "        # Use Pandas to load the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Drop columns that are entirely empty\n",
    "        df = drop_empty_columns(df)\n",
    "\n",
    "        # Use 'to_sql' to insert the data into the database, it creates a table if it does not exist\n",
    "        df.to_sql('loan_level_data', engine, if_exists='append', index=False)\n",
    "\n",
    "print(\"Loading data completed. All empty columns were dropped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7502d65a-6c0e-46ea-b185-9d748186a963",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
